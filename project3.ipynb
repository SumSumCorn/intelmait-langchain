{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "- LLMChain\n",
    "- Sequential Chains\n",
    "  - SimpleSequentialChain\n",
    "  - SequentialChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 모든 것을 하나의 체인으로 결합할 수 있습니다.  \n",
    "이 체인은 입력 변수를 받아 프롬프트 템플릿으로 전달하여 프롬프트를 생성하고,  \n",
    "프롬프트를 LLM으로 전달한 다음 (선택 사항인) 출력 파서를 통해 출력을 전달합니다.\n",
    "\n",
    "모듈식 로직을 번들로 묶는 편리한 방법입니다. 실제로 사용해 봅시다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고기', '채소', '과일', '양념', '면식료']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "\n",
    "template = \"\"\"너는 쉼표로 구분된 목록을 생성하는 ai야.\n",
    "사용자가 카테고리를 전달하면 해당 카테고리의 객체 5개를 쉼표로 구분된 목록으로 생성해.\n",
    "쉼표로 구분된 목록만 반환함.\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(), prompt=chat_prompt, output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"음식\")\n",
    "# >> ['red', 'blue', 'green', 'yellow', 'orange']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
